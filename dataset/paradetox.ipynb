{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using the pre-trained available BART-ParaDetox model, we run all of the comments in Jigsaw dataset through it to generate its parallel detoxed dataset.\n",
    "2. Using the generated parallel dataset, we use it to train our own BART model\n",
    "3. The trained BART model will then be used to generate the detoxified sentence of any input sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the python environment\n",
    "Ideally you run the following cells with the virtual environment created using python3 (anything before 3.10 version works from our testing) with the packages specified in the `requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and load the Jigsaw dataset with the relevant columns:\n",
    "- `comment_text` : the column containing the input toxic sentence\n",
    "- `toxicity` : the column cotaining the toxicity score of the input toxic sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generating the parallel dataset from Jigsaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_data.csv')\n",
    "target_columns = ['comment_text', 'toxicity', 'severe_toxicity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = re.sub(r'http\\S+', '', text) # Remove URLs\n",
    "        text = re.sub(r'[^\\w\\s]', '', text) # Remove punctuation\n",
    "        text = text.lower()\n",
    "        # Handle self-censored words and emojis as needed\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        return \"\"\n",
    "    return text\n",
    "\n",
    "# cleaned = df['comment_text'].apply(clean_text)\n",
    "# cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hope they're both beaten to death in the can. Should have gotten the death penalty. Says everything about Kansas social services. It's a sick country.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"s-nlp/bart-base-detox\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"s-nlp/bart-base-detox\")\n",
    "# 'that sick fuck is going to be out in 54 years.', \n",
    "toxics = [\"Hope they're both beaten to death in the can. Should have gotten the death penalty. Says everything about Kansas social services. It's a sick country.\"]\n",
    "tokens = tokenizer(toxics, return_tensors='pt', padding=True)\n",
    "tokens = model.generate(**tokens, num_return_sequences=1, do_sample=False,\n",
    "                        temperature=1.0, repetition_penalty=10.0,\n",
    "                        max_length=128, num_beams=5)\n",
    "neutrals = tokenizer.decode(tokens[0, ...], skip_special_tokens=True)\n",
    "print(neutrals) # stdout: She is going to be out in 54 years.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
