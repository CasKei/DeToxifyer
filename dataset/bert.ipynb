{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to normalise data (?)\n",
    "def normalise_x(inputX):\n",
    "  min_max_scaler = preprocessing.MinMaxScaler()\n",
    "  dfToNorm_scaled = min_max_scaler.fit_transform(inputX)\n",
    "  x = pd.DataFrame(dfToNorm_scaled)\n",
    "  return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Preprocessing texts in dataset \n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = re.sub(r'http\\S+', '', text) # Remove URLs\n",
    "        text = re.sub(r'[^\\w\\s]', '', text) # Remove punctuation\n",
    "        text = text.lower()\n",
    "        # Handle self-censored words and emojis as needed\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        return \"\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_toxic\n",
      "0    1570549\n",
      "1     428967\n",
      "Name: count, dtype: int64\n",
      "is_toxic\n",
      "0    428967\n",
      "1    428967\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Read data and train test split\n",
    "data = pd.read_csv('all_data.csv')\n",
    "data['cleaned_text'] = data['comment_text'].apply(clean_text)\n",
    "data.columns\n",
    "# Specify the columns to consider for toxicity\n",
    "toxic_columns = ['toxicity', 'severe_toxicity', 'obscene', 'sexual_explicit', 'identity_attack', 'insult', 'threat']\n",
    "\n",
    "# # function to normalise data (?) \n",
    "# def normalise_x(inputX): \n",
    "#     min_max_scaler = preprocessing.MinMaxScaler() \n",
    "#     dfToNorm_scaled = min_max_scaler.fit_transform(inputX) \n",
    "#     x = pd.DataFrame(dfToNorm_scaled) \n",
    "#     return x\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# Normalize the specified columns \n",
    "#data[toxic_columns] = scaler.fit_transform(data[toxic_columns])\n",
    "\n",
    "# Print the normalized data\n",
    "#print(\"Normalized Data\")\n",
    "#print(data[toxic_columns].head())\n",
    "\n",
    "\n",
    "# Update the 'toxicity' label based on the values in the specified columns\n",
    "data['is_toxic'] = 0\n",
    "data['is_toxic'] = data.apply(lambda row: 1 if any(row[col] >= 0.2 for col in toxic_columns) else row['is_toxic'], axis=1)\n",
    "\n",
    "# Check the updated class distribution\n",
    "print(data['is_toxic'].value_counts())\n",
    "\n",
    "# Calculate the ratio of toxic to non-toxic samples\n",
    "toxic_count = data['is_toxic'].sum()\n",
    "non_toxic_count = len(data) - toxic_count\n",
    "ratio = non_toxic_count / toxic_count\n",
    "\n",
    "# If the ratio is still above a certain threshold, remove some non-toxic samples\n",
    "if ratio > 2:  # Adjust the threshold as per your requirement\n",
    "    non_toxic_data = data[data['is_toxic'] == 0]\n",
    "    toxic_data = data[data['is_toxic'] == 1]\n",
    "    \n",
    "    # Randomly select a subset of non-toxic samples to keep\n",
    "    num_samples_to_keep = int(toxic_count)  # Adjust the factor as per your requirement\n",
    "    non_toxic_data = non_toxic_data.sample(n=num_samples_to_keep, random_state=42)\n",
    "    \n",
    "    # Combine the toxic and selected non-toxic samples\n",
    "    data = pd.concat([toxic_data, non_toxic_data])\n",
    "    \n",
    "    # Shuffle the data\n",
    "    data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(data['is_toxic'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         ... 0.6        0.64436297 1.        ]\n"
     ]
    }
   ],
   "source": [
    "a = np.sort(data['severe_toxicity'])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698152 159782\n"
     ]
    }
   ],
   "source": [
    "# make label binary 1 and 0 first for toxicity\n",
    "data['is_toxic'] = (data['toxicity'] >= 0.5).astype(int)\n",
    " \n",
    "count_zero = np.sum(data['is_toxic']  == 0) \n",
    "count_one = np.sum(data['is_toxic']  == 1)\n",
    "print(count_zero, count_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698152 159782\n"
     ]
    }
   ],
   "source": [
    "\n",
    "count_zero = np.sum(data['is_toxic']  == 0)\n",
    "count_one = np.sum(data['is_toxic']  == 1)\n",
    "\n",
    "print(count_zero, count_one)\n",
    "X = data['cleaned_text']\n",
    "y = data['is_toxic']\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chong\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2645: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    X_train.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    X_validation.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    X_test.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# cuda\n",
    "device = torch.device(\"cuda\")\n",
    "device\n",
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "scalar = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert lists to tensors\n",
    "\n",
    "train_seq = torch.tensor(scalar.fit_transform(tokens_train['input_ids'])).long().to(device)\n",
    "train_mask = torch.tensor(tokens_train['attention_mask']).to(device)\n",
    "train_y = torch.tensor(y_train.tolist()).to(device)\n",
    "\n",
    "val_seq = torch.tensor(scalar.fit_transform(tokens_val['input_ids'])).long().to(device)\n",
    "val_mask = torch.tensor(tokens_val['attention_mask']).to(device)\n",
    "val_y = torch.tensor(y_validation.tolist()).to(device)\n",
    "\n",
    "test_seq = torch.tensor(scalar.fit_transform(tokens_test['input_ids'])).long().to(device)\n",
    "test_mask = torch.tensor(tokens_test['attention_mask']).to(device)\n",
    "test_y = torch.tensor(y_test.tolist()).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "test_data = TensorDataset(test_seq, test_mask, test_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "\n",
    "# dataLoader for testidation set\n",
    "test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        \n",
    "        self.bert = bert \n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "      \n",
    "        # relu activation function\n",
    "        self.relu =  nn.ReLU()\n",
    "\n",
    "        # dense layer 1\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "      \n",
    "        # dense layer 2 (Output layer)\n",
    "        self.fc2 = nn.Linear(512,32)\n",
    "\n",
    "        #softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "        \n",
    "        #pass the inputs to the model  \n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
    "      \n",
    "        x = self.fc1(cls_hs)\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # output layer\n",
    "        x = self.fc2(x)\n",
    "      \n",
    "        # apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT_Arch(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (fc1): Linear(in_features=768, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=32, bias=True)\n",
      "  (softmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chong\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# optimizer from hugging face transformers\n",
    "# The compute_class_weight function from the sklearn.utils.class_weight module is used to compute the class weights with multiple parameters for the training labels.\n",
    "from transformers import AdamW\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(),lr = 1e-3)\n",
    "\n",
    "#compute the class weights\n",
    "# class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train.tolist()), y=y_train.tolist())\n",
    "\n",
    "# print('Class Weights:',class_weights)\n",
    "# print('number of weights: ', len(class_weights))\n",
    "# print('number of classes: ', len(np.unique(y_train.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting list of class weights to a tensor\n",
    "# weights= torch.tensor(class_weights,dtype=torch.float)\n",
    "\n",
    "# push to GPU\n",
    "# weights = weights.to(device)\n",
    "\n",
    "# define the loss function\n",
    "mse_loss  = nn.MSELoss() \n",
    "\n",
    "# number of training epochs\n",
    "epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "    \n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "    # empty list to save model predictions\n",
    "    total_preds=[]\n",
    "  \n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(train_dataloader):\n",
    "        \n",
    "        # progress update after every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "        \n",
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    " \n",
    "        sent_id, mask, labels = batch\n",
    "        \n",
    "        # clear previously calculated gradients \n",
    "        model.zero_grad()        \n",
    "\n",
    "        # get model predictions for the current batch\n",
    "        preds = model(sent_id, mask)\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = mse_loss(preds, labels.float())\n",
    "\n",
    "        # add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        preds=preds.detach().cpu().numpy()\n",
    "\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "\n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "      # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "      # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    #returns the loss and predictions\n",
    "    return avg_loss, total_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate(dataloader):\n",
    "    \n",
    "    print(\"\\nEvaluating...\")\n",
    "  \n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    \n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "\n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(dataloader):\n",
    "        \n",
    "        # Progress update every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            \n",
    "            # Calculate elapsed time in minutes.\n",
    "            # elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask)\n",
    "\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = mse_loss(preds,labels.float())\n",
    "\n",
    "            total_loss = total_loss + loss.item()\n",
    "\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "\n",
    "            total_preds.append(preds)\n",
    "\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(dataloader) \n",
    "\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    50  of  21,449.\n",
      "  Batch   100  of  21,449.\n",
      "  Batch   150  of  21,449.\n",
      "  Batch   200  of  21,449.\n",
      "  Batch   250  of  21,449.\n",
      "  Batch   300  of  21,449.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Epoch \u001b[39m\u001b[38;5;132;01m{:}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{:}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, epochs))\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#train model\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m train_loss, _ \u001b[38;5;241m=\u001b[39m train()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#evaluate model\u001b[39;00m\n\u001b[0;32m     20\u001b[0m valid_loss, _ \u001b[38;5;241m=\u001b[39m evaluate(val_dataloader)\n",
      "Cell \u001b[1;32mIn[52], line 31\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m loss \u001b[38;5;241m=\u001b[39m mse_loss(preds, labels\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# add on to the total loss\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m+\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# backward pass to calculate the gradients\u001b[39;00m\n\u001b[0;32m     34\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "#defining epochs\n",
    "epochs = 5\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate(val_dataloader)\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # get predictions for test data \n",
    "# with torch.no_grad(): \n",
    "#     preds = model(test_seq.to(device), test_mask.to(device)) \n",
    "#     preds = preds.detach().cpu().numpy() \n",
    " \n",
    "\n",
    "# # model's performance\n",
    "# preds = np.argmax(preds, axis = 1)\n",
    "# print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch \n",
    " \n",
    "# # save tagged_data \n",
    "# # with open('tagged_data.pickle', 'wb') as handle: \n",
    "# #     pickle.dump(tagged_data, handle, protocol=pickle.HIGHEST_PROTOCOL) \n",
    " \n",
    "# # open and load tags from pickle file \n",
    "# model = BERT_Arch(bert)\n",
    "# # model = BERT_Arch(*args, **kwargs)\n",
    "# model.load_state_dict(torch.load('saved_weights2.pt'))\n",
    "# model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n",
      "  Batch    50  of  2,682.\n",
      "  Batch   100  of  2,682.\n",
      "  Batch   150  of  2,682.\n",
      "  Batch   200  of  2,682.\n",
      "  Batch   250  of  2,682.\n",
      "  Batch   300  of  2,682.\n",
      "  Batch   350  of  2,682.\n",
      "  Batch   400  of  2,682.\n",
      "  Batch   450  of  2,682.\n",
      "  Batch   500  of  2,682.\n",
      "  Batch   550  of  2,682.\n",
      "  Batch   600  of  2,682.\n",
      "  Batch   650  of  2,682.\n",
      "  Batch   700  of  2,682.\n",
      "  Batch   750  of  2,682.\n",
      "  Batch   800  of  2,682.\n",
      "  Batch   850  of  2,682.\n",
      "  Batch   900  of  2,682.\n",
      "  Batch   950  of  2,682.\n",
      "  Batch 1,000  of  2,682.\n",
      "  Batch 1,050  of  2,682.\n",
      "  Batch 1,100  of  2,682.\n",
      "  Batch 1,150  of  2,682.\n",
      "  Batch 1,200  of  2,682.\n",
      "  Batch 1,250  of  2,682.\n",
      "  Batch 1,300  of  2,682.\n",
      "  Batch 1,350  of  2,682.\n",
      "  Batch 1,400  of  2,682.\n",
      "  Batch 1,450  of  2,682.\n",
      "  Batch 1,500  of  2,682.\n",
      "  Batch 1,550  of  2,682.\n",
      "  Batch 1,600  of  2,682.\n",
      "  Batch 1,650  of  2,682.\n",
      "  Batch 1,700  of  2,682.\n",
      "  Batch 1,750  of  2,682.\n",
      "  Batch 1,800  of  2,682.\n",
      "  Batch 1,850  of  2,682.\n",
      "  Batch 1,900  of  2,682.\n",
      "  Batch 1,950  of  2,682.\n",
      "  Batch 2,000  of  2,682.\n",
      "  Batch 2,050  of  2,682.\n",
      "  Batch 2,100  of  2,682.\n",
      "  Batch 2,150  of  2,682.\n",
      "  Batch 2,200  of  2,682.\n",
      "  Batch 2,250  of  2,682.\n",
      "  Batch 2,300  of  2,682.\n",
      "  Batch 2,350  of  2,682.\n",
      "  Batch 2,400  of  2,682.\n",
      "  Batch 2,450  of  2,682.\n",
      "  Batch 2,500  of  2,682.\n",
      "  Batch 2,550  of  2,682.\n",
      "  Batch 2,600  of  2,682.\n",
      "  Batch 2,650  of  2,682.\n"
     ]
    }
   ],
   "source": [
    "model.to('cuda')\n",
    "loss, tt_preds = evaluate(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90     69710\n",
      "           1       0.00      0.00      0.00     16084\n",
      "\n",
      "    accuracy                           0.81     85794\n",
      "   macro avg       0.41      0.50      0.45     85794\n",
      "weighted avg       0.66      0.81      0.73     85794\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CasKei\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\CasKei\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\CasKei\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# # get predictions for test data \n",
    "# with torch.no_grad(): \n",
    "#     preds = model(test_seq.to(device), test_mask.to(device)) \n",
    "#     preds = preds.detach().cpu().numpy() \n",
    " \n",
    " \n",
    "# # model's performance \n",
    "# preds = np.argmax(preds, axis = 1) \n",
    "# print(classification_report(test_y, preds))\n",
    "\n",
    "\n",
    "# tt_preds = tt_preds.to('cpu')\n",
    "\n",
    "torch_tensor = torch.from_numpy(tt_preds)\n",
    "cpu_tensor = torch_tensor.cpu()\n",
    "\n",
    "# model's performance \n",
    "preds = np.argmax(cpu_tensor, axis = 1) \n",
    "print(classification_report(test_y.cpu(), preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.6614221  -0.72591186]\n",
      " [-0.6614221  -0.72591186]\n",
      " [-0.6614221  -0.72591186]\n",
      " ...\n",
      " [-0.6614221  -0.72591186]\n",
      " [-0.65912205 -0.728371  ]\n",
      " [-0.6614221  -0.72591186]]\n"
     ]
    }
   ],
   "source": [
    "print(tt_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0')\n",
      "[-0.6614221  -0.72591186]\n"
     ]
    }
   ],
   "source": [
    "print(test_y[22])\n",
    "print(tt_preds[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.51611686 0.4838831 ]\n",
      " [0.51611686 0.4838831 ]\n",
      " [0.51611686 0.4838831 ]\n",
      " ...\n",
      " [0.51611686 0.4838831 ]\n",
      " [0.5173053  0.48269466]\n",
      " [0.51611686 0.4838831 ]]\n"
     ]
    }
   ],
   "source": [
    "# import torch.nn.functional as F\n",
    "\n",
    "# tt_torched = torch.from_numpy(tt_preds)\n",
    "# r1 = F.log_softmax(tt_torched, dim=-1)\n",
    "# print(r1)\n",
    "\n",
    "exp_logits = np.exp(tt_preds)\n",
    "print(exp_logits)\n",
    "# Calculate the softmax probabilities\n",
    "# softmax_probabilities = exp_logits / np.sum(exp_logits)\n",
    "\n",
    "# softmax_probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_predictions = np.argmax(exp_logits, axis=1)\n",
    "class_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(class_predictions[:30])\n",
    "print(test_y[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
