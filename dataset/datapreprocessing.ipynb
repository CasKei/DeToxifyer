{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Processing for Logistic Regression"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "import numpy as np\n",
            "import pandas as pd\n",
            "import seaborn as sns\n",
            "import matplotlib.pyplot as plt\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "Index(['id', 'comment_text', 'split', 'created_date', 'publication_id',\n",
                     "       'parent_id', 'article_id', 'rating', 'funny', 'wow', 'sad', 'likes',\n",
                     "       'disagree', 'toxicity', 'severe_toxicity', 'obscene', 'sexual_explicit',\n",
                     "       'identity_attack', 'insult', 'threat', 'male', 'female', 'transgender',\n",
                     "       'other_gender', 'heterosexual', 'homosexual_gay_or_lesbian', 'bisexual',\n",
                     "       'other_sexual_orientation', 'christian', 'jewish', 'muslim', 'hindu',\n",
                     "       'buddhist', 'atheist', 'other_religion', 'black', 'white', 'asian',\n",
                     "       'latino', 'other_race_or_ethnicity', 'physical_disability',\n",
                     "       'intellectual_or_learning_disability', 'psychiatric_or_mental_illness',\n",
                     "       'other_disability', 'identity_annotator_count',\n",
                     "       'toxicity_annotator_count'],\n",
                     "      dtype='object')"
                  ]
               },
               "execution_count": 3,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "df = pd.read_csv('all_data.csv')\n",
            "\n",
            "df.columns"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## A bit useless"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>id</th>\n",
                     "      <th>comment_text</th>\n",
                     "      <th>split</th>\n",
                     "      <th>publication_id</th>\n",
                     "      <th>parent_id</th>\n",
                     "      <th>article_id</th>\n",
                     "      <th>toxicity</th>\n",
                     "      <th>severe_toxicity</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>596097</th>\n",
                     "      <td>5801652</td>\n",
                     "      <td>Awesome! Lets cut the head off hate! Lets stab...</td>\n",
                     "      <td>train</td>\n",
                     "      <td>21</td>\n",
                     "      <td>NaN</td>\n",
                     "      <td>368010</td>\n",
                     "      <td>1.000000</td>\n",
                     "      <td>1.000000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>207189</th>\n",
                     "      <td>5997855</td>\n",
                     "      <td>You are murdering feckless SCUM.  Your mother ...</td>\n",
                     "      <td>train</td>\n",
                     "      <td>102</td>\n",
                     "      <td>NaN</td>\n",
                     "      <td>379957</td>\n",
                     "      <td>0.983501</td>\n",
                     "      <td>0.644363</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>601973</th>\n",
                     "      <td>5883664</td>\n",
                     "      <td>.\\n.\\nIs there really a God ?\\n... I once thou...</td>\n",
                     "      <td>train</td>\n",
                     "      <td>53</td>\n",
                     "      <td>5879007.0</td>\n",
                     "      <td>373036</td>\n",
                     "      <td>0.900000</td>\n",
                     "      <td>0.600000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>461912</th>\n",
                     "      <td>6180251</td>\n",
                     "      <td>DOGS----\\nEAT\\nSHIT\\nSLEEP\\nBARK\\n\\nNIGERS\\nEA...</td>\n",
                     "      <td>train</td>\n",
                     "      <td>21</td>\n",
                     "      <td>6179746.0</td>\n",
                     "      <td>390746</td>\n",
                     "      <td>0.990396</td>\n",
                     "      <td>0.591236</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>528865</th>\n",
                     "      <td>5754942</td>\n",
                     "      <td>BURN THIS DOG RAPING WHITE NIGER ALIVE\\nTIME f...</td>\n",
                     "      <td>train</td>\n",
                     "      <td>105</td>\n",
                     "      <td>NaN</td>\n",
                     "      <td>365110</td>\n",
                     "      <td>0.973936</td>\n",
                     "      <td>0.569070</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>...</th>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>1999483</th>\n",
                     "      <td>6248884</td>\n",
                     "      <td>Most Illegal Aliens strongly believe in Racist...</td>\n",
                     "      <td>train</td>\n",
                     "      <td>55</td>\n",
                     "      <td>6248837.0</td>\n",
                     "      <td>394615</td>\n",
                     "      <td>0.400000</td>\n",
                     "      <td>0.000000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>56</th>\n",
                     "      <td>5276309</td>\n",
                     "      <td>The parallels between the ANC and the Sicilian...</td>\n",
                     "      <td>train</td>\n",
                     "      <td>100</td>\n",
                     "      <td>NaN</td>\n",
                     "      <td>335763</td>\n",
                     "      <td>0.833333</td>\n",
                     "      <td>0.000000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>1999491</th>\n",
                     "      <td>5950800</td>\n",
                     "      <td>Now here is an example of what I consider to b...</td>\n",
                     "      <td>train</td>\n",
                     "      <td>55</td>\n",
                     "      <td>5950675.0</td>\n",
                     "      <td>377568</td>\n",
                     "      <td>0.400000</td>\n",
                     "      <td>0.000000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>59</th>\n",
                     "      <td>7175529</td>\n",
                     "      <td>I have, Don Nom De Lantinos PoliticallyIncorre...</td>\n",
                     "      <td>test</td>\n",
                     "      <td>13</td>\n",
                     "      <td>471117.0</td>\n",
                     "      <td>145656</td>\n",
                     "      <td>0.090909</td>\n",
                     "      <td>0.000000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>1499636</th>\n",
                     "      <td>1043803</td>\n",
                     "      <td>On a scale of one to one thousand the Herzberg...</td>\n",
                     "      <td>train</td>\n",
                     "      <td>54</td>\n",
                     "      <td>NaN</td>\n",
                     "      <td>166701</td>\n",
                     "      <td>0.166667</td>\n",
                     "      <td>0.000000</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "<p>1999516 rows Ã— 8 columns</p>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "              id                                       comment_text  split  \\\n",
                     "596097   5801652  Awesome! Lets cut the head off hate! Lets stab...  train   \n",
                     "207189   5997855  You are murdering feckless SCUM.  Your mother ...  train   \n",
                     "601973   5883664  .\\n.\\nIs there really a God ?\\n... I once thou...  train   \n",
                     "461912   6180251  DOGS----\\nEAT\\nSHIT\\nSLEEP\\nBARK\\n\\nNIGERS\\nEA...  train   \n",
                     "528865   5754942  BURN THIS DOG RAPING WHITE NIGER ALIVE\\nTIME f...  train   \n",
                     "...          ...                                                ...    ...   \n",
                     "1999483  6248884  Most Illegal Aliens strongly believe in Racist...  train   \n",
                     "56       5276309  The parallels between the ANC and the Sicilian...  train   \n",
                     "1999491  5950800  Now here is an example of what I consider to b...  train   \n",
                     "59       7175529  I have, Don Nom De Lantinos PoliticallyIncorre...   test   \n",
                     "1499636  1043803  On a scale of one to one thousand the Herzberg...  train   \n",
                     "\n",
                     "         publication_id  parent_id  article_id  toxicity  severe_toxicity  \n",
                     "596097               21        NaN      368010  1.000000         1.000000  \n",
                     "207189              102        NaN      379957  0.983501         0.644363  \n",
                     "601973               53  5879007.0      373036  0.900000         0.600000  \n",
                     "461912               21  6179746.0      390746  0.990396         0.591236  \n",
                     "528865              105        NaN      365110  0.973936         0.569070  \n",
                     "...                 ...        ...         ...       ...              ...  \n",
                     "1999483              55  6248837.0      394615  0.400000         0.000000  \n",
                     "56                  100        NaN      335763  0.833333         0.000000  \n",
                     "1999491              55  5950675.0      377568  0.400000         0.000000  \n",
                     "59                   13   471117.0      145656  0.090909         0.000000  \n",
                     "1499636              54        NaN      166701  0.166667         0.000000  \n",
                     "\n",
                     "[1999516 rows x 8 columns]"
                  ]
               },
               "execution_count": 4,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "newdf = df[['id', 'comment_text', 'split', 'publication_id',\n",
            "       'parent_id', 'article_id', 'toxicity', 'severe_toxicity']]\n",
            "\n",
            "newdf = newdf.sort_values(by='severe_toxicity', ascending=False)\n",
            "newdf"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Data Cleaning"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [],
         "source": [
            "import re\n",
            "def clean_text(text):\n",
            "    if isinstance(text, str):\n",
            "        text = re.sub(r'http\\S+', '', text) # Remove URLs\n",
            "        text = re.sub(r'[^\\w\\s]', '', text) # Remove punctuation\n",
            "        text = text.lower()\n",
            "        # Handle self-censored words and emojis as needed\n",
            "        pass\n",
            "    \n",
            "    else:\n",
            "        return \"\"\n",
            "    return text\n",
            "\n",
            "# cleaned = df['comment_text'].apply(clean_text)\n",
            "# cleaned\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Delete rows to 'balance' the dataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "is_toxic\n",
                  "0    1570549\n",
                  "1     428967\n",
                  "Name: count, dtype: int64\n"
               ]
            }
         ],
         "source": [
            "# Read data and train test split\n",
            "data = pd.read_csv('all_data.csv')\n",
            "data['cleaned_text'] = data['comment_text'].apply(clean_text)\n",
            "data.columns\n",
            "# Specify the columns to consider for toxicity\n",
            "toxic_columns = ['toxicity', 'severe_toxicity', 'obscene', 'sexual_explicit', 'identity_attack', 'insult', 'threat']\n",
            "\n",
            "# # function to normalise data (?) \n",
            "# def normalise_x(inputX): \n",
            "#     min_max_scaler = preprocessing.MinMaxScaler() \n",
            "#     dfToNorm_scaled = min_max_scaler.fit_transform(inputX) \n",
            "#     x = pd.DataFrame(dfToNorm_scaled) \n",
            "#     return x\n",
            "\n",
            "# Create a MinMaxScaler object\n",
            "# scaler = preprocessing.MinMaxScaler()\n",
            "\n",
            "# Normalize the specified columns \n",
            "#data[toxic_columns] = scaler.fit_transform(data[toxic_columns])\n",
            "\n",
            "# Print the normalized data\n",
            "#print(\"Normalized Data\")\n",
            "#print(data[toxic_columns].head())\n",
            "\n",
            "\n",
            "# Update the 'toxicity' label based on the values in the specified columns\n",
            "data['is_toxic'] = 0\n",
            "data['is_toxic'] = data.apply(lambda row: 1 if any(row[col] >= 0.2 for col in toxic_columns) else row['is_toxic'], axis=1)\n",
            "\n",
            "# Check the updated class distribution\n",
            "print(data['is_toxic'].value_counts())\n",
            "\n",
            "# Calculate the ratio of toxic to non-toxic samples\n",
            "toxic_count = data['is_toxic'].sum()\n",
            "non_toxic_count = len(data) - toxic_count\n",
            "ratio = non_toxic_count / toxic_count\n",
            "\n",
            "# If the ratio is still above a certain threshold, remove some non-toxic samples\n",
            "if ratio > 2:  # Adjust the threshold as per your requirement\n",
            "    non_toxic_data = data[data['is_toxic'] == 0]\n",
            "    toxic_data = data[data['is_toxic'] == 1]\n",
            "    \n",
            "    # Randomly select a subset of non-toxic samples to keep\n",
            "    num_samples_to_keep = int(toxic_count)  # Adjust the factor as per your requirement\n",
            "    non_toxic_data = non_toxic_data.sample(n=num_samples_to_keep, random_state=42)\n",
            "    \n",
            "    # Combine the toxic and selected non-toxic samples\n",
            "    data = pd.concat([toxic_data, non_toxic_data])\n",
            "    \n",
            "    # Shuffle the data\n",
            "    data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Save the processed data as a new csv"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [],
         "source": [
            "data.to_csv('cleaned_data.csv', index=False)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Tokenization"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "[nltk_data] Downloading package punkt to\n",
                  "[nltk_data]     C:\\Users\\CasKei\\AppData\\Roaming\\nltk_data...\n",
                  "[nltk_data]   Package punkt is already up-to-date!\n"
               ]
            },
            {
               "data": {
                  "text/plain": [
                     "True"
                  ]
               },
               "execution_count": 10,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "from gensim.models.doc2vec import Doc2Vec,\\\n",
            "    TaggedDocument\n",
            "from nltk.tokenize import word_tokenize\n",
            "import nltk\n",
            "nltk.download('punkt')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [],
         "source": [
            "# preprocess to make a big list of sentences\n",
            "tagged_data = [TaggedDocument(words=word_tokenize(_d), tags=[str(i)]) for i, _d in enumerate(data['cleaned_text'])]\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Save the tokenized data as a pickle"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "import pickle\n",
            "\n",
            "# save tagged_data\n",
            "# with open('tagged_data.pickle', 'wb') as handle:\n",
            "#     pickle.dump(tagged_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
            "tagged_data = ''\n",
            "# open and load tags from pickle file\n",
            "with open('tagged_data.pickle', 'rb') as handle:\n",
            "    tagged_data = pickle.load(handle)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Doc2Vec training"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [],
         "source": [
            "# train the Doc2vec model\n",
            "model = Doc2Vec(vector_size=20,\n",
            "                min_count=2, epochs=10)\n",
            "model.build_vocab(tagged_data)\n",
            "model.train(tagged_data,\n",
            "            total_examples=model.corpus_count,\n",
            "            epochs=model.epochs)\n",
            " \n",
            "# get the document vectors\n",
            "document_vectors = [model.infer_vector(\n",
            "    word_tokenize(doc)) for doc in data['cleaned_text']]\n",
            " \n",
            "# #  print the document vectors\n",
            "# for i, doc in enumerate(cleaned):\n",
            "#     print(\"Document\", i+1, \":\", doc)\n",
            "#     print(\"Vector:\", document_vectors[i])\n",
            "#     print()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Save trained document vectors"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [],
         "source": [
            "# save\n",
            "with open('LR_document_vectors.pickle', 'wb') as handle:\n",
            "    pickle.dump(document_vectors, handle, protocol=pickle.HIGHEST_PROTOCOL)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "857934\n",
                  "857934\n"
               ]
            }
         ],
         "source": [
            "print(len(document_vectors))\n",
            "print(len(data))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "base",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.9.18"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
