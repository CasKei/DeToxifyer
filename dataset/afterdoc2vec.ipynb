{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load document vectors from `dataprocessing` ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text', 'split', 'created_date', 'publication_id',\n",
       "       'parent_id', 'article_id', 'rating', 'funny', 'wow', 'sad', 'likes',\n",
       "       'disagree', 'toxicity', 'severe_toxicity', 'obscene', 'sexual_explicit',\n",
       "       'identity_attack', 'insult', 'threat', 'male', 'female', 'transgender',\n",
       "       'other_gender', 'heterosexual', 'homosexual_gay_or_lesbian', 'bisexual',\n",
       "       'other_sexual_orientation', 'christian', 'jewish', 'muslim', 'hindu',\n",
       "       'buddhist', 'atheist', 'other_religion', 'black', 'white', 'asian',\n",
       "       'latino', 'other_race_or_ethnicity', 'physical_disability',\n",
       "       'intellectual_or_learning_disability', 'psychiatric_or_mental_illness',\n",
       "       'other_disability', 'identity_annotator_count',\n",
       "       'toxicity_annotator_count', 'cleaned_text', 'is_toxic'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')\n",
    "\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "X = ''\n",
    "# open and load tags from pickle file\n",
    "# with open('document_vectors.pickle', 'rb') as handle:\n",
    "#     X = pickle.load(handle)\n",
    "\n",
    "with open('LR_document_vectors.pickle', 'rb') as handle:\n",
    "    X = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857934 857934\n"
     ]
    }
   ],
   "source": [
    "# combined files with the word embeddings and labels\n",
    "y = df['is_toxic']\n",
    "# y = np.where(df['toxicity']>=0.5, 1, 0)\n",
    "print(len(X), len(y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6669114390283702\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "# X = [doc2vec_model.infer_vector(doc.words) for doc in tagged_data]\n",
    "# y = [doc.tags[0] for doc in tagged_data]\n",
    "\n",
    "# # Split data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train logistic regression classifier\n",
    "logreg_classifier = LogisticRegression()\n",
    "logreg_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = logreg_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74905141 0.58741639 0.28185649 0.20795242 0.05247452 0.52864872\n",
      " 0.61905166 0.54465442 0.7304845  0.45306829 0.33209656 0.20506908\n",
      " 0.86102194 0.49922397 0.28777097 0.7260824  0.36289393 0.30558214\n",
      " 0.37011201 0.43164269 0.0758166  0.34006381 0.35297228 0.47274113\n",
      " 0.0382508  0.70498946 0.78529529 0.61375058 0.36547252 0.77546721]\n",
      "523432    1\n",
      "721108    1\n",
      "195647    0\n",
      "418740    0\n",
      "725922    1\n",
      "209455    1\n",
      "679707    1\n",
      "647453    1\n",
      "435284    0\n",
      "804960    0\n",
      "341759    0\n",
      "809882    1\n",
      "707604    1\n",
      "742187    1\n",
      "186174    1\n",
      "416267    1\n",
      "455788    0\n",
      "264423    0\n",
      "809465    0\n",
      "731031    1\n",
      "740538    1\n",
      "166709    1\n",
      "645939    1\n",
      "468541    0\n",
      "469709    0\n",
      "614761    1\n",
      "772259    1\n",
      "439648    1\n",
      "60366     0\n",
      "764883    1\n",
      "Name: is_toxic, dtype: int64\n",
      "[1 1 0 0 0 1 1 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "predictions_proba = logreg_classifier.predict_proba(X_test)[:30, 1] \n",
    "print(predictions_proba)\n",
    "\n",
    "print(y_test[:30])\n",
    "print(y_pred[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LR_model.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib \n",
    " \n",
    "# save \n",
    "joblib.dump(logreg_classifier, \"LR_model.pkl\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load \n",
    "clf2 = joblib.load(\"LR_model.pkl\") \n",
    " \n",
    "clf2.predict(X_test[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
