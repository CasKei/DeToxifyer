{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import nltk\n",
    "import lxml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt     \n",
    "from tqdm import tqdm\n",
    "from gensim.models import doc2vec\n",
    "from sklearn import utils\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentences(corpus, label_type):\n",
    "    \"\"\"\n",
    "    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
    "    a dummy index of the post.\n",
    "    \"\"\"\n",
    "    labeled = []\n",
    "    for i, v in enumerate(corpus):\n",
    "        label = label_type + '_' + str(i)\n",
    "        labeled.append(doc2vec.TaggedDocument(str(v).split(), [label]))\n",
    "    return labeled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unsplit_data_d2v():\n",
    "  y = df[\"Target\"]\n",
    "  x_lyrics = df[\"Lyrics\"]\n",
    "\n",
    "  return x_lyrics, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_data_d2v(x, y):\n",
    "  split = split_data(x, y)\n",
    "  x_train =split[0][0]\n",
    "  y_train = split[0][1]\n",
    "  x_val = split[1][0]\n",
    "  y_val = split[1][1]\n",
    "  x_test = split[2][0]\n",
    "  y_test = split[2][1]\n",
    "\n",
    "  x_train_val = np.concatenate((x_train, x_val))\n",
    "  y_train_val = np.concatenate((y_train, y_val))\n",
    "\n",
    "  x_train_labelled = label_sentences(x_train_val, 'Train')\n",
    "  x_test_labelled = label_sentences(x_test, 'Test')\n",
    "  all_data = x_train_labelled + x_test_labelled\n",
    "\n",
    "  return {\"all_data\": all_data, \"y_train\": y_train_val, \"y_test\": y_test, \"len_x_train\": len(x_train_val), \"len_x_test\": len(x_test)}\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_dbow_func (vector_size, all_data):\n",
    "  model_dbow = doc2vec.Doc2Vec(dm=0, vector_size=vector_size, negative=5, min_count=1, alpha=0.065, \n",
    "                     min_alpha=0.065)\n",
    "  model_dbow.build_vocab([x for x in tqdm(all_data)])\n",
    "  return model_dbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_d2v_model(model_dbow, all_data):\n",
    "  for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), \n",
    "                     total_examples=len(all_data), \n",
    "                     epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha\n",
    "\n",
    "  return model_dbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
    "    \"\"\"\n",
    "    Get vectors from trained doc2vec model\n",
    "    :param doc2vec_model: Trained Doc2Vec model\n",
    "    :param corpus_size: Size of the data\n",
    "    :param vectors_size: Size of the embedding vectors\n",
    "    :param vectors_type: Training or Testing vectors\n",
    "    :return: list of vectors\n",
    "    \"\"\"\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    for i in range(0, corpus_size):\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "        vectors[i] = model.docvecs[prefix]\n",
    "    return vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorise(vector_size, model_dbow, len_x_train, len_x_test):\n",
    "  train_vectors_dbow = get_vectors(model_dbow, len_x_train, vector_size, 'Train')\n",
    "  test_vectors_dbow = get_vectors(model_dbow, len_x_test, vector_size, 'Test')\n",
    "\n",
    "  return train_vectors_dbow, test_vectors_dbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_sizes = [10, 20, 50, 100, 200, 500]\n",
    "\n",
    "def optimal_vector_size_d2v():\n",
    "\n",
    "  x, y = get_unsplit_data_d2v()\n",
    "  data_dict = get_split_data_d2v(x, y)\n",
    "\n",
    "  all_data = data_dict[\"all_data\"]\n",
    "  y_train = data_dict[\"y_train\"]\n",
    "  y_test = data_dict[\"y_test\"]\n",
    "  len_x_train = data_dict[\"len_x_train\"]\n",
    "  len_x_test = data_dict[\"len_x_test\"]\n",
    "\n",
    "  result = {}\n",
    "  for size in vector_sizes:\n",
    "    d2v_model = model_dbow_func(size, all_data)\n",
    "    trained_d2v_model = train_d2v_model(d2v_model, all_data)\n",
    "    train_vectors, test_vectors = vectorise(size, trained_d2v_model, len_x_train, len_x_test)\n",
    "\n",
    "    accuracy, pred_prob = run_NN_vectors(train_vectors, test_vectors, y_train, y_test)\n",
    "    result[size] = accuracy, pred_prob\n",
    "\n",
    "    print(f\"Size: {size}, Accuracy: {accuracy}\")\n",
    "\n",
    "  return result\n",
    "\n",
    "optimal_vector_size_d2v()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
